\documentclass[a4paper,11pt]{article}

\usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}
\usepackage{fancyhdr} \usepackage{graphicx,subfig} \usepackage{lastpage}
\usepackage{amssymb,amsmath} \usepackage{siunitx} \usepackage[nodayofweek]{datetime}
\usepackage[top=3.5cm,bottom=2.5cm,left=3cm,right=3cm,headheight=40pt]{geometry}
\usepackage{parskip} \usepackage{float} \usepackage{enumitem} \pagestyle{fancy}
\usepackage[colorlinks=true,allcolors=blue]{hyperref} \hypersetup{
	pdfauthor={Michaël Defferrard},
	pdftitle={Project stage 2: Rendering},
	pdfsubject={Introduction to Computer Graphics}
}

\lhead{Introduction to Computer Graphics\\Project stage 2: Rendering\\Group 19}
\chead{\hspace{2.5cm}EPFL\\\hspace{2.5cm}\shortdate\today\\\hspace{2.5cm}\thepage/\pageref{LastPage}}
\rhead{Michaël \textsc{Defferrard}\\Pierre \textsc{Fechting}\\Vu Hiep \textsc{Doan}}
\cfoot{}

\begin{document}


\section{Overview}

This report presents our advancement on the second part of the project : rendering using procedural methods. Figure~ shows an example of what our actual code base is able to generate. All the minimal steps to display a procedurally generated terrain were successfully completed. We did also implement some other optional suggested methods, like 

With this stage, we realized that we are better technicians than artists.

\section{Implementation}

\subsection{Basics}

\subsubsection{Texturing}

In this part, our idea is that we can use whatever texture that we want, whatever method or way of blending that we want as long as the terrain looks realistic. Also, the way we implement texture blending is trial and errors, we try many different ways of blending and continue in the direction that generates better results.

\begin{figure}[ht]
	\centering
	\includegraphics[height=4cm]{{{img_stage2/texture_blending_with_specular}}}
	\caption{The terrain with blended texture.}
	\label{texture_blending}
\end{figure}

\subsubsection{Modeling the sky}

For this part, the idea is very straightforward as we try to render two objects : terrain and a textured cube covered the terrain and display them together on the screen. However, it is very time-consuming to implement but good things are after finishing this part, we can gain a very solid understanding of OpenGL vertex buffer mechanism.

To render multiple objects together, before rendering each object, we set its frame buffer as a render target and bind the vertex array of that object. In addition, we use separate program to render each object, so before drawing it, we need to call \texttt{glUseProgram} in OpenGL.

To texturize the skybox with sky images, we make use of \texttt{GL\_CUBE\_MAP\_SEAMLESS} option in OpenGL to get rid of the problem with seams. We also note that for high-resolution texture files, which are $1024 \cdot 1024 \cdot 3=3\textrm{MB}$ each, are too big to be allocated on the stack so they need to be placed also on the heap.

The results of this part is shown in Figure~\ref{skybox}.

\begin{figure}[ht]
	\centering
	\includegraphics[height=4cm]{{{img_stage2/skybox}}}
	\caption{The terrain covered by a sky box.}
	\label{skybox}
\end{figure}
\subsubsection{Self shadowing}


\subsection{Advanced}

\subsubsection{Approximating water reflections/refractions}

\subsubsection{Water depth effect (participating media)}

\subsubsection{Water dynamics}
For this part, we follow a very simple approach. In the vertex shader of the terrain generation, for only vertices belonging to the water region, we displace it in z-direction by a sin function of x and y position (up to a scale). We also pass a uniform variable \texttt{time} to control the phase of the displacement. Even this is super simple but the result is pretty good. 

In addition, we also do normal mapping for water region. Instead of calculating the normal like other regions, we do a normal vector lookup in the normal map and use that vector for shading. 

\subsubsection{Time of the day}


\section{Improvements on last stage}

\subsection{Code modularization using object oriented programming}

We re-factored our code base to use an object oriented paradigm. This allows better modularization and generalization. The idea is to have a base class (\texttt{RenderingContext}) who defines the interface and implements common methods. The contexts (\texttt{Terrain}, \texttt{Skybox} and \texttt{Shadow}) then inherits from it and implement further specializations. This simplifies the manipulation of the contexts from the main program as they all have the same interface. A common implementation also limits code duplication.

This is similar to what is proposed in the hand-out. With however a major difference : we wanted to separate the class declaration and definition (i.e. implementation) in a header and a source file. There is two motivations behind this : putting the declaration in a header makes it easy for the class user to identify methods and parameters he can use; putting the definition in a separate compilation unit isolates the code.

The problem we encountered with this approach is that the OpenGP headers (included from \texttt{common.h}) do not contain only declarations, but also definitions (i.e. code). Such that we cannot include the \texttt{common.h} header in more than one compilation unit. If we did so, the linker would complain appropriately about multiple definitions of the same functions. We thus created an \texttt{opengp.h} header who declares (and not defines) the functions and constants from OpenGP used in our project. Their definitions (included from \texttt{common.h}) are solely included in the main compilation unit. This is a workaround but it allows to use a proper object oriented paradigm with one declaration and one definition file per object without modifying the provided framework.

\subsection{Parameter tuning for better terrain generation}

In order to find a better terrain, several combination method has been tested. The first idea was to use an hybrid multi fractal method based on 1 minus the absolute value generated by perlin noise. After tuning parameters, we found a terrain counting few lacs and really sharp mountains as shown Figure \ref{hybridmultifractal_terrain}. Such terrain doesn't contain flat plain, therefor we tested a multi fractal method combining perlin and simplex noise as shown Figure \ref{multifractal_perlin_simplex_terrain}. Oppositely to the hybrid multi-fractal, this method generates flat plains but smooth mountains.

\begin{figure}[H]
	\centering
	\subfloat[Hybrid multi-fractal based on Perlin noise]{
		\label{hybridmultifractal_terrain}
		\includegraphics[height=4cm]{{{img_stage2/hybridmultifractal}}}
	} \quad
	\subfloat[Multi-fractal based on perlin and simplex noise]{
		\label{multifractal_perlin_simplex_terrain}
		\includegraphics[height=4cm]{{{img_stage2/multifractal_perlin_simplex_noise}}}
	} \quad
	\caption{Terrain generated}
\end{figure}

As we developed several generating method in project part 1, an idea is to combine them.\\
Additive combination: sum the product of a coefficient and the height generated by fractal Brownian motion, multi-fractal (simplex noise based), multi-fractal(perlin noise based), simplex noise and perlin noise. The sum of coefficients must be equal to 1 in order to have a balanced and well scaled terrain. As we have 5 coefficients variating from 0.1 to 1.0, we have 102 possible combinations ( for a sum of coefficient equal to 1). We used an external software called "autoit" to generate the 102 combinations. Using autoit, we wrote a loop setting the coefficients, generating the terrain and saving a snapshot of it. Two example of generated terrain using this method are shown Figures \ref{additive_combination1}, \ref{additive_combination1}.

\begin{figure}[H]
	\centering
	\subfloat[Example 1]{
		\label{additive_combination1}
		\includegraphics[height=4cm]{{{img_stage2/1_terrain_coefs_0.2_0.4_0.1_0.1_0.2}}}
	} \quad
	\subfloat[Example 2]{
		\label{additive_combination2}
		\includegraphics[height=4cm]{{{img_stage2/1_terrain_coefs_0.4_0.2_0.1_0.1_0.2}}}
	} \quad
	\caption{Additive combination}
\end{figure}

Random combination: use different noise and multi-fractal methods according to a randomly generated number. Using randomly a different noise per pixel leads to a highly discontinuous  terrain with abrupt change of height as shown Figure \ref{random_combination}

\begin{figure}[H]
	\centering
	\includegraphics[height=4cm]{{{img_stage2/random_combination}}}
	\caption{Random combination}
	\label{random_combination}
\end{figure}

Spatial combination: use several noise and multi-fractal methods multiplied by a coefficient computed according to the x or y position. This method will smoothly superpose different terrain generation methods creating sharp mountains with lacs and flat plains as shown figures \ref{spatial_combination1} and \ref{spatial_combination2}.

\begin{figure}[H]
	\centering
	\subfloat[Example 1]{
		\label{spatial_combination1}
		\includegraphics[height=4cm]{{{img_stage2/spatial_combination1}}}
	} \quad
	\subfloat[Example 2]{
		\label{spatial_combination2}
		\includegraphics[height=4cm]{{{img_stage2/spatial_combination2}}}
	} \quad
	\caption{Spatial combination}
\end{figure}

\subsection{Fixing normal vector calculation}

The normal vector calculation implemented in previous stage is actually not correct but only until we try to blend the texture based on the normal vector that we recognize that the results are not correct. While it costs us a lot of time to re-implement normal vector calculation, the experience that we learned when correcting the normal vector is really invaluable for further understanding OpenGL pipeline.

Firstly, we map the world coordinate to a texel before using \texttt{textureOffset} function to look up the height of surrounding texels in both x and y direction. A finite difference is used to approximate the tangent vector to the surface at that point on the height map then finally, a normal vector will be just the cross product of tangent vectors along x and y directions.

In addition, the above normal vector is just in height map coordinate (ranging from $[0,1] \times [0,1]$ in xy plane) so we need to map it to our world coordinate of the grid ([-1,1] in xy plane). Note that when transform the normal vector, we actually need to multiply it with the inverse of transpose matrix of the transformed one.

To test the normal vector, we output it as the color of each fragment as shown in Figure~\ref{normal_vector}. We can see that the result is quite reasonable, for example in the ground part as it is flat region, the normal vector should be (0,0,1) and as a result, its color is blue.

\begin{figure}[ht]
	\centering
	\includegraphics[height=4cm]{{{img_stage2/normal_vector}}}
	\caption{The terrain is colored by its own normal vector.}
	\label{normal_vector}
\end{figure}

\section{Results}


\end{document}
